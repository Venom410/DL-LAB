{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0bedfb-3221-499e-b7f8-4aaf4a9b6e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/da: tensor(64.)\n",
      "dz/db: tensor(249.)\n"
     ]
    }
   ],
   "source": [
    "#q1\n",
    "import torch\n",
    "\n",
    "a = torch.tensor(2.0,requires_grad=True)\n",
    "b = torch.tensor(3.0,requires_grad=True)\n",
    "\n",
    "x = (2 * a) + (3 * b)\n",
    "y = (5 * a * a) + (3 * b * b * b)\n",
    "z = (2 * x) + (3 * y)\n",
    "z.backward()\n",
    "\n",
    "print(\"dz/da:\", a.grad)\n",
    "print(\"dz/db:\", b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745406e5-a75d-44de-a61c-421dce8cd261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient da/dw computed using PyTorch: 0.0027305022813379765\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the variables with requires_grad=True to track gradients\n",
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# Calculate intermediate values\n",
    "u = w * x\n",
    "v = u + torch.tensor([1.0])  # Assuming b = 1 for simplicity\n",
    "a = torch.relu(v)\n",
    "\n",
    "# Perform backward propagation to compute gradients\n",
    "a.backward()\n",
    "\n",
    "# Access the gradient da/dw\n",
    "gradient_da_dw = w.grad\n",
    "\n",
    "# Print the result\n",
    "print(\"Gradient da/dw computed using PyTorch:\", gradient_da_dw.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7003590-8d69-482b-aa98-a902826cf44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient da/dw computed using PyTorch: 0.0027305022813379765\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the variables with requires_grad=True to track gradients\n",
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "# Calculate intermediate values\n",
    "u = w * x\n",
    "v = u + b\n",
    "a = torch.sigmoid(v)\n",
    "\n",
    "# Perform backward propagation to compute gradients\n",
    "a.backward()\n",
    "\n",
    "# Access the gradient da/dw\n",
    "gradient_da_dw = w.grad\n",
    "\n",
    "# Print the result\n",
    "print(\"Gradient da/dw computed using PyTorch:\", gradient_da_dw.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d463f8-ca49-4d9b-930a-67965f02bf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value in forward prop : tensor(0.0001, grad_fn=<ExpBackward0>)\n",
      "df/dx : tensor(-0.0008)\n"
     ]
    }
   ],
   "source": [
    "#q4\n",
    "import torch\n",
    "def func(x):\n",
    "    return torch.exp(-(x*x)-(2*x)-torch.sin(x))\n",
    "\n",
    "x = torch.tensor(2.0,requires_grad=True)\n",
    "f = func(x)\n",
    "print(\"value in forward prop :\",f)\n",
    "\n",
    "f.backward()\n",
    "\n",
    "print(\"df/dx :\",x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b546466f-16c8-4f6a-b93d-1a61d85ca2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx : tensor(326.)\n"
     ]
    }
   ],
   "source": [
    "#q5\n",
    "import torch\n",
    "\n",
    "x = torch.tensor(2.0,requires_grad=True)\n",
    "y = (8*x**4) + (3*x**3) + (7*x**2) + (6*x) + 3\n",
    "y.backward()\n",
    "\n",
    "print(\"dy/dx :\",x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e9ac0c-86e2-4be6-8400-133dcba2a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values in forward pass :\n",
      "\n",
      "a : tensor(2., grad_fn=<MulBackward0>)\n",
      "b : tensor(0.9093, grad_fn=<SinBackward0>)\n",
      "c : tensor(2.1995, grad_fn=<DivBackward0>)\n",
      "d : tensor(6.5985, grad_fn=<MulBackward0>)\n",
      "e : tensor(2.0280, grad_fn=<LogBackward0>)\n",
      "f : tensor(0.9660, grad_fn=<TanhBackward0>)\n",
      "values in backward pass :\n",
      "df/dx : tensor(0.0581)\n",
      "df/dy : tensor(0.0266)\n",
      "df/dz : tensor(0.0194)\n"
     ]
    }
   ],
   "source": [
    "#q6\n",
    "import torch\n",
    "x = torch.tensor(1.0,requires_grad=True)\n",
    "y = torch.tensor(2.0,requires_grad=True)\n",
    "z = torch.tensor(3.0,requires_grad=True)\n",
    "\n",
    "a = 2*x\n",
    "b = torch.sin(y)\n",
    "c = a/b\n",
    "d = c*z\n",
    "e = torch.log(d+1)\n",
    "f = torch.tanh(e)\n",
    "print(\"values in forward pass :\\n\")\n",
    "print(\"a :\",a)\n",
    "print(\"b :\",b)\n",
    "print(\"c :\",c)\n",
    "print(\"d :\",d)\n",
    "print(\"e :\",e)\n",
    "print(\"f :\",f)\n",
    "f.backward()\n",
    "print(\"values in backward pass :\")\n",
    "print(\"df/dx :\",x.grad)\n",
    "print(\"df/dy :\",y.grad)\n",
    "print(\"df/dz :\",z.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc5bc3-5c8f-49bc-922c-f3bed500029c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
